<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<!--  <link rel="icon" href="assets/xhr.ico" type="image/x-icon">-->
  <link rel="apple-touch-icon" sizes="180x180" href="assets/favicon_package/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="assets/favicon_package/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="assets/favicon_package/favicon-16x16.png">
  <link rel="manifest" href="assets/favicon_package/site.webmanifest">
  <link rel="mask-icon" href="assets/favicon_package/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="preload" href="assets/fonts/xxx.woff" as="font" type="font/woff" crossorigin>

  <title>Haoran (Ryan) Xu</title>
  <meta name="description" content="">

  <link rel="stylesheet" href="main.css">
  <link rel="canonical" href="ryanxhr.github.io">
  <link rel="preload" href="assets/font/Mukta-Light.ttf" as="font" type="font/woff" crossorigin>
  <link rel="preload" href="assets/font/Mukta-Medium.ttf" as="font" type="font/woff" crossorigin>

  <!-- <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Mukta:wght@300;400&display=swap" rel="stylesheet"> -->
  <!-- <style>
    a { color: #FF0000; } /* CSS link color */
  </style> -->
</head>

<body data-new-gr-c-s-check-loaded="14.1029.0" data-gr-ext-installed="">

  <main class="page-content" aria-label="Content">
    <div class="wrapper">

      <article class="post">
        <div class="post-content">
          <img src="assets/xhr.jpg" class="profile-picture">

          <p>
              Hello! I am Haoran Xu (ÂæêÊµ©ÁÑ∂ in Chinese). I am now at <a href="https://air.tsinghua.edu.cn/en/">Institute for AI Industry Research (AIR), Tsinghua University</a> (I will join <a href="https://www.utexas.edu/">UT Austin</a> to start my Ph.D. study in Fall 2023). Previously, I interned at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a> and worked at <a href="https://corporate.jd.com/">JD.com</a> on data-driven Reinforcement Learning and its applications. I obtained Bachelor & Master's degree from <a href="https://en.xidian.edu.cn/">Xidian University</a>, advised by <a href="http://zhanxianyuan.xyz/">Xianyuan Zhan</a> and <a href="http://urban-computing.com/yuzheng">Zheng Yu</a>. I also work closely with <a href="https://www.princeton.edu/~zy6/">Zhuoran Yang</a> and <a href="https://zhaoranwang.github.io/">Zhaoran Wang</a>.
          </p>

          <p>
              My ultimate dream is to maximally leveraging prior information to facilitate the development of machine autonomy. Towards this goal, my research primarily focused on <strong>offline RL</strong>, <strong>imitation learning</strong>, and <strong>human-in-the-loop RL</strong>. I am open to collaboration, feel free to reach me out!
<!--              and aims to answer the central question: <strong>How can we maximally leverage existing knowledge and computational work, such as collected data, human priors, and learned policies, to accelerate training and drive towards a safe, reliable and generalizable autonomous agent?</strong> -->
          </p>

          <p>
            Some links: <a href="assets/xhr_cv_new.pdf"><span>CV (Last updated on Feb. 2023)</span></a> /
            <a href="https://github.com/ryanxhr">Github</i></span></a> /
            <a href="https://twitter.com/ryanxhr">Twitter</a> /
            <a href="https://scholar.google.com/citations?user=iX8AJI0AAAAJ"><span>Google Scholar</span></a> /
            <a href="mailto:haoran.xu@utexas.edu">haoran.xu@utexas.edu</a>
          </p>

          <!-- <strong>I am actively looking for postdoc and full research positions. Weclome to drop me an email if interested.</strong> -->

        </div>
      </article>
    </div>

    <div class="wrapper">
      <!-- <article class="post"> -->
        <header class="post-header">
          <h1 class="post-title">News </h1>
        </header>
        <article class="post">
          <ul>
            <li>üá∑üáº I am attending ICLR 2023 in-person at Kigali! </li>
            <li>üåü Three papers I like very much on offline RL and reward learning are accepted to <strong>ICLR 2023</strong>! </li>
            <li>Honored to be selected as <a href="https://neurips.cc/Conferences/2022/ProgramCommittee">Top Reviewers in NeurIPS 2022</a>. </li>
            <li>One paper on offline RL is accepted to <strong>NeurIPS 2022</strong>! </li>
            <li>One paper on offline IL is accepted to <strong>ICML 2022</strong>! </li>
          </ul>
        </article>
    </div>

    <div class="wrapper">
      <article class="post">
        <header class="post-header">
          <h1 class="post-title" id="Publications">Publications <span style="font-size:small;letter-spacing:0.00px;">(* marks equal contribution)</a></span> </h1>
          <!-- <span class="footnote">* marks equal contribution</span> -->
        </header> 
      </article>
    <!-- Tab links -->
    <div class="tab">
      <button class="tablinks" onclick="openCity(event, 'Selected')" id="defaultOpen">üåü Selected</button>
      <button class="tablinks" onclick="openCity(event, 'All')">üìö All</button>
<!--      <button class="tablinks" onclick="openCity(event, 'Unsupervised')">üéÇ Unsupervised Learning</button>-->
<!--      <button class="tablinks" onclick="openCity(event, 'Adversarial')">üî® Robust Learning</button>-->
<!--      <button class="tablinks" onclick="openCity(event, 'Graph')">üåê Graph Learning</button>-->
    </div>

    <!-- Tab content -->
    <div id="Selected" class="tabcontent">
      <!-- <h3>Selected</h3> -->
      <ul class="publications">

        <li class="article">
          <span class="title">
            Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization
          </span>
              <span class="authors"><strong>Haoran Xu</strong>, Li Jiang, Jianxiong Li, Zhuoran Yang, Zhaoran Wang, Victor Wai Kin Chan, Xianyuan Zhan </span>
              <span class="journal-info">ICLR 2023</span>
              <span class="oral">(Notable Top 5%)</span>
              <span class="year">2023</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2303.15810">Paper</a> |
            <a href="https://github.com/ryanxhr/IVR">Code</a> |
            <a href="https://docs.google.com/presentation/d/1Apo0L0sNMi9gNjRx3nizRzwbJ5sD9oEW7XOeZP_k_d0/edit?usp=sharing">Slides</a>
          </span>
        </li>

          <li class="article">
          <span class="title">
            A Policy-Guided Imitation Approach for Offline Reinforcement Learning
          </span>
              <span class="authors"><strong>Haoran Xu*</strong>, Li Jiang*, Jianxiong Li, Xianyuan Zhan </span>
              <span class="journal-info">NeurIPS 2022</span>
              <span class="oral">(Oral, Top 2%)</span>
              <span class="year">2023</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2210.08323">Paper</a> |
            <a href="https://github.com/ryanxhr/POR">Code</a> |
            <a href="https://docs.google.com/presentation/d/1swZTLDSvZLGCrXs46tzSHLWZC6VfO9qYChegjjadCpc/edit?usp=sharing">Slides</a> |
            <a href="https://mp.weixin.qq.com/s/a6u2Wwfus6PtBziKfMB1zg">Media </a>
          </span>
          </li>
        
        <li class="article">
          <span class="title">
          Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations
          </span>
              <span class="authors"><strong>Haoran Xu</strong>, Xianyuan Zhan, Honglei Yin, Huiling Qin</span>
              <span class="journal-info">ICML 2022  </span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2207.10050">Paper</a> |
            <a href="https://github.com/ryanxhr/DWBC">Code</a> |
            <a href="https://docs.google.com/presentation/d/1WS8farSLxi1MDrG5C5FUfF9iarMgwZ1MAbfAuOeUyQw/edit?usp=sharing">Slides</a>
          </span>
        </li>

        <li class="article">
          <span class="title">
          Constraints Penalized Q-Learning for Safe Offline Reinforcement Learning
          </span>
              <span class="authors"><strong>Haoran Xu</strong>, Xianyuan Zhan, Xiangyu Zhu</span>
              <span class="journal-info">AAAI 2022</span>
              <span class="oral">(Spotlight @ ICML 2021 RL4RealLife workshop)</span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2107.09003">Paper</a> |
            <a href="https://github.com/ryanxhr/CPQ">Code</a> |
            <a href="https://docs.google.com/presentation/d/1i9mgy_YZabzwk7zHzJ9FL72HBW2cZkSiGdGBIO5roAU/edit?usp=sharing">Slides</a>
          </span>
        </li>

      <li class="article">
        <span class="title">
        DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning
        </span>
            <span class="authors">Xianyuan Zhan*, <strong>Haoran Xu*</strong>, Yue Zhang, Yusen Huo, Xiangyu Zhu, Honglei Yin, Yu Zheng</span>
            <span class="journal-info">AAAI 2022</span>
            <span class="oral">(Spotlight @ ICML 2021 RL4RealLife workshop)</span>
            <span class="year">2022</span>
            <span class="links">
          <a href="https://arxiv.org/abs/2102.11492">Paper</a> |
          <a href="https://github.com/ryanxhr/DeepThermal">Code</a>
        </span>
      </li>
    </ul>

    </div>


    <div id="All" class="tabcontent">
      <ul class="publications">
          <li class="article">
          <span class="title">
            PROTO: Iterative Policy Regularized Offline-to-Online Reinforcement Learning
          </span>
              <span class="authors">Jianxiong Li, Xiao Hu, <strong>Haoran Xu</strong>, , Jingjing Liu, Xianyuan Zhan, Ya-Qin Zhang </span>
              <span class="journal-info">Preprint, under review</span>
              <span class="year">2023</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2305.15669">Paper</a> |
            <a href="https://github.com/Facebear-ljx/PROTO">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
            SaFormer: A Conditional Sequence Modeling Approach to Offline Safe Reinforcement Learning
          </span>
          <span class="authors">Qin Zhang*, Linrui Zhang*, <strong>Haoran Xu</strong>, Li Shen, Bowen Wang, Xueqian Wang, Bo Yuan, Yongzhe Chang, Dacheng Tao </span>
          <span class="journal-info">ICLR 2023 SR4AD Workshop</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://arxiv.org/abs/2301.12203">Paper</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
            Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization
          </span>
              <span class="authors"><strong>Haoran Xu</strong>, Li Jiang, Jianxiong Li, Zhuoran Yang, Zhaoran Wang, Victor Wai Kin Chan, Xianyuan Zhan </span>
              <span class="journal-info">ICLR 2023</span>
              <span class="oral">(Notable Top 5%)</span>
              <span class="year">2023</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2303.15810">Paper</a> |
            <a href="https://github.com/ryanxhr/IVR">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
            Mind the Gap: Offline Policy Optimizaiton for Imperfect Rewards
          </span>
              <span class="authors">Jianxiong Li, Xiao Hu, <strong>Haoran Xu</strong>, Jingjing Liu, Xianyuan Zhan, Qing-Shan Jia, Ya-Qin Zhang </span>
              <span class="journal-info">ICLR 2023</span>
              <span class="year">2023</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2302.01667">Paper</a> |
            <a href="https://github.com/Facebear-ljx/RGM">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
            When data geometry meets deep function: Generalizing offline reinforcement learning
          </span>
              <span class="authors">Jianxiong Li, Xianyuan Zhan, <strong>Haoran Xu</strong>, Xiangyu Zhu, Jingjing Liu, Ya-Qin Zhang </span>
              <span class="journal-info">ICLR 2023</span>
              <span class="year">2023</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2205.11027">Paper</a> |
            <a href="https://github.com/Facebear-ljx/DOGE">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
            A Policy-Guided Imitation Approach for Offline Reinforcement Learning
          </span>
              <span class="authors"><strong>Haoran Xu*</strong>, Li Jiang*, Jianxiong Li, Xianyuan Zhan </span>
              <span class="journal-info">NeurIPS 2022</span>
              <span class="oral">(Oral, Top 2%)</span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2210.08323">Paper</a> |
            <a href="https://github.com/ryanxhr/POR">Code</a> |
            <a href="https://docs.google.com/presentation/d/1swZTLDSvZLGCrXs46tzSHLWZC6VfO9qYChegjjadCpc/edit?usp=sharing">Slides</a> |
            <a href="https://mp.weixin.qq.com/s/a6u2Wwfus6PtBziKfMB1zg">Media </a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations
          </span>
              <span class="authors"><strong>Haoran Xu</strong>, Xianyuan Zhan, Honglei Yin, Huiling Qin</span>
              <span class="journal-info">ICML 2022  </span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2207.10050">Paper</a> |
            <a href="https://github.com/ryanxhr/DWBC">Code</a> |
            <a href="https://docs.google.com/presentation/d/1WS8farSLxi1MDrG5C5FUfF9iarMgwZ1MAbfAuOeUyQw/edit?usp=sharing">Slides</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          Constraints Penalized Q-Learning for Safe Offline Reinforcement Learning
          </span>
              <span class="authors"><strong>Haoran Xu</strong>, Xianyuan Zhan, Xiangyu Zhu</span>
              <span class="journal-info">AAAI 2022</span>
              <span class="oral">(Spotlight @ ICML 2021 RL4RealLife workshop)</span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2107.09003">Paper</a> |
            <a href="https://github.com/ryanxhr/CPQ">Code</a> |
            <a href="https://docs.google.com/presentation/d/1i9mgy_YZabzwk7zHzJ9FL72HBW2cZkSiGdGBIO5roAU/edit?usp=sharing">Slides</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning
          </span>
              <span class="authors">Xianyuan Zhan*, <strong>Haoran Xu*</strong>, Yue Zhang, Yusen Huo, Xiangyu Zhu, Honglei Yin, Yu Zheng</span>
              <span class="journal-info">AAAI 2022</span>
              <span class="oral">(Spotlight @ ICML 2021 RL4RealLife workshop)</span>
              <span class="year">2022</span>
              <span class="links">
          <a href="https://arxiv.org/abs/2102.11492">Paper</a> |
          <a href="https://github.com/ryanxhr/DeepThermal">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          Discriminator-Guided Model-Based Offline Imitation Learning
          </span>
              <span class="authors">Wenjia Zhang, <strong>Haoran Xu</strong>, Haoyi Niu, Peng Cheng, Ming Li, Heming Zhang, Guyue Zhou, Xianyuan Zhan</span>
              <span class="journal-info">CoRL 2022</span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2207.00244">Paper</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          Model-Based Offline Planning with Trajectory Pruning
          </span>
              <span class="authors">Xianyuan Zhan, Xiangyu Zhu, <strong>Haoran Xu</strong></span>
              <span class="journal-info">IJCAI 2022</span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2105.07351">Paper</a> |
            <a href="https://github.com/zhanzxy5/MOPP">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          ECoalVis: Visual Analysis of Control Strategies in Coal-fired Power Plants
          </span>
              <span class="authors">Shuhan Liu, Di Weng, Yuan Tian, Zikun Deng, <strong>Haoran Xu</strong>, Xiangyu Zhu, Honglei Yin, Xianyuan Zhan, Yingcai Wu</span>
              <span class="journal-info">IEEE VIS 2022</span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://ieeexplore.ieee.org/abstract/document/9908527">Paper</a> |
            <a href="https://github.com/ECoalVis/ECoalVis">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          Multi-Memory enhanced Separation Network for Indoor Temperature Prediction
          </span>
              <span class="authors">Zhewen Duan, Xiuwen Yi, Peng Li, Dekang Qi, Yexin Li, <strong>Haoran Xu</strong>, Yanyong Huang, Junbo Zhang, Yu Zheng</span>
              <span class="journal-info">DASFAA 2022</span>
              <span class="year">2022</span>
              <span class="links">
            <a href="https://link.springer.com/chapter/10.1007/978-3-031-00126-0_49?noAccess=true">Paper</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          Offline Reinforcement Learning with Soft Behavioral Regularization
          </span>
              <span class="authors"><strong>Haoran Xu</strong>, Xianyuan Zhan, Jianxiong Li, Honglei Yin</span>
              <span class="journal-info">NeurIPS 2021 Offline RL Workshop</span>
              <span class="year">2021</span>
              <span class="links">
            <a href="https://arxiv.org/abs/2110.07395">Paper</a> |
            <a href="https://github.com/Facebear-ljx/SBAC">Code</a>
          </span>
          </li>

          <li class="article">
          <span class="title">
          Robust Spatio-Temporal Purchase Prediction via Deep Meta Learning
          </span>
              <span class="authors">Huiling Qin, Songyu Ke, Xiaodu Yang, <strong>Haoran Xu</strong>, Xianyuan Zhan, Yu Zheng</span>
              <span class="journal-info">AAAI 2021</span>
              <span class="year">2021</span>
              <span class="links">
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/16556">Paper</a>
          </span>
          </li>

      </ul>
    </div>

  </div>

      <!--    <div class="wrapper">-->
<!--      <article class="post">-->
<!--        <header class="post-header">-->
<!--        <h1 class="post-title">Awards</h1>-->
<!--        </header>-->
<!--        <div class="post-content">-->
<!--          <strong><a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Best ML Paper Award</a></strong> (1/685), ECML-PKDD, 2021 <br>-->
<!--          &lt;!&ndash; <a href="https://advml-workshop.github.io/icml2021/" style="color:#000000;"> &ndash;&gt;-->
<!--            <strong><a href="https://advml-workshop.github.io/icml2021/">Silver Best Paper Award</a></strong>, ICML AML workshop, 2021<br>-->
<!--          <strong>National Scholarship</strong>, Ministry of Education of China, 2021, 2022 <br>-->
<!--          <strong>Principal Scholarship</strong>, Peking University, 2022 <br>-->
<!--          <strong>Baidu Scholarship Nomination Award</strong> (20 worldwide), Baidu Inc, 2022 <br>-->
<!--      </div>-->
<!--    </div>-->

    <div class="wrapper">
      <article class="post">
        <header class="post-header">
        <h1 class="post-title">Professional Services</h1>
        </header>
        <div class="post-content">
        Reviewer for NeurIPS, ICML, AAAI
        </div>
      </article>
    </div>

<!--  <div class="wrapper">-->
<!--    <article class="post">-->
<!--      <header class="post-header">-->
<!--      <h1 class="post-title">Teaching</h1>-->
<!--      </header>-->
<!--      <div class="post-content">-->
<!--      2022 Spring, TA in <strong>Advances in Machine Learning</strong>, instructed by Prof. Yisen Wang. <br>-->
<!--      2021 Spring, TA in <strong>Trustworthy Machine Learning</strong>, instructed by Prof. Yisen Wang. <br>-->
<!--      2018 Spring, TA in <strong>Optimization in Machine Learning</strong>, instructed by Prof. Zhouchen Lin. <br>-->
<!--      2017 Fall, TA in <strong>Machine Learning</strong>, instructed by Prof. Tong Lin. <br>-->
<!--      </div>-->
<!--    </article>-->
<!--  </div>-->

<!--    <div class="wrapper">-->
<!--      <article class="post">-->
<!--        <header class="post-header">-->
<!--        <h1 class="post-title">Students Advised</h1>-->
<!--        </header>-->
<!--        <div class="post-content">-->
<!--            I have been lucky to co-advise a number of talented undergraduate and master‚Äôs students at Stanford, who have written some very insightful papers:-->

<!--            I have also mentored (and often proposed research directions) for a number of fantastic PhD students who have taught me a lot:-->

<!--        </div>-->
<!--      </article>-->
<!--    </div>-->

<!--      <div class="wrapper">-->
<!--          <article class="post">-->
<!--              <header class="post-header">-->
<!--                  <h1 class="post-title">Collaborators and Advisors</h1>-->
<!--              </header>-->
<!--              <div class="post-content">-->
<!--                  I spent a wonderful summer working with Suriya Gunasekar and Sebastien Bubeck in the Microsoft Research Foundations Group. During my PhD I‚Äôve also been lucky to collaborate with Aditi Raghunathan, Sang Michael Xie, Chelsea Finn, and Zico Kolter, and learn a lot from John Duchi. Before my PhD, I spent a fun year working at DeepMind, and before that did undergraduate research work with Avrim Blum, Guy Blelloch, and Bob Harper.-->
<!--              </div>-->
<!--          </article>-->
<!--      </div>-->





      <!--<script-->
<!--        type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=LISh56gffeAxOYBOk45sr6LRD7c60rWH1uPJOca6hLs&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'>-->
<!--</script>-->


<script>
  // Check if API exists
  if (document && document.fonts) {    
    // Do not block page loading
    setTimeout(function () {           
      document.fonts.load('16px "Mukta"').then(() => {
        // Make font using elements visible
        document.documentElement.classList.add('font-loaded') 
      })
    }, 0)
  } else {
    // Fallback if API does not exist 
    document.documentElement.classList.add('font-loaded') 
  }
</script>

<script>
  function openCity(evt, cityName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
      tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
      tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(cityName).style.display = "block";
    evt.currentTarget.className += " active";
  }
// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
  </script>

  </footer>
